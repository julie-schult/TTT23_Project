{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\MachineLearning\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "print(Path.cwd())\n",
    "sys.path.insert(0, str(Path.cwd() / \"..\"))\n",
    "from image_normalization.image_norm import setGrayToBlack, paddImage, rotate, rotate_same_dim\n",
    "from pymage_size import get_image_size\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are ï»¿path, ROI1, ROI2, ROI3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def readImages(csvPath):    \n",
    "    \"\"\"\n",
    "    Reads the images, sets the grayscale values to black, i.e. removes all the area without a \n",
    "    heatmap. Converts remaining image to grayscale and pads, to make every image equal in size.\n",
    "    \n",
    "    TODO: instead of converting to grayscale with BGR2GRAY convert to grayscale where red is\n",
    "    white and purple is black\n",
    "\n",
    "    returns the images and an array y of the roi values. \n",
    "    \"\"\"\n",
    "    filenames = []\n",
    "    roi = []\n",
    "    max_shape = [0, 0]\n",
    "    with open(csvPath) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                path = Path.cwd() / \"..\" / row[0]\n",
    "                filenames.append(str(path))\n",
    "                img_size = get_image_size(str(path)).get_dimensions()[::-1]\n",
    "                if img_size[0] > max_shape[0]:\n",
    "                    max_shape[0] = img_size[0]\n",
    "                if img_size[1] > max_shape[1]:\n",
    "                    max_shape[1] = img_size[1]\n",
    "\n",
    "                roi.append([float(row[1]), float(row[2]), float(row[3])])\n",
    "\n",
    "    y = np.zeros((len(filenames), 3), float)\n",
    "    images = np.zeros((len(filenames), max_shape[0], max_shape[1]), dtype=np.uint8) \n",
    "    for i, filepath in enumerate(filenames):\n",
    "        img = cv.imread(str(filepath))\n",
    "        # cv.imshow(\"img1\", img)\n",
    "        img_black = setGrayToBlack(img, threshold=150)\n",
    "        # cv.imshow(\"img_gray_black\", img_black)\n",
    "\n",
    "        img_gray = cv.cvtColor(img_black, cv.COLOR_BGR2GRAY)\n",
    "        # cv.imshow(\"img_gray\", img_gray)\n",
    "        img_pad = paddImage(img_gray, max_shape)\n",
    "        # cv.imshow(\"pad\", img_pad)\n",
    "        images[i] = img_pad\n",
    "        y[i] = np.array(roi[i])\n",
    "        # cv.waitKey(0)\n",
    "        # cv.destroyAllWindows()\n",
    "        # return\n",
    "    return images, y\n",
    "\n",
    "images, y = readImages(r\"C:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\Rawdata_values.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split date into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment training set. This could be done on the initial set aswell, but then the test set would be of a \"lower\" quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train(X, Y):\n",
    "\n",
    "    numAugment = np.random.randint(3, 11, size=(len(X)))\n",
    "    X_out = np.zeros((len(X) + np.sum(numAugment), X.shape[1], X.shape[2]), dtype=X.dtype)\n",
    "    Y_out = np.zeros((len(Y) + np.sum(numAugment), Y.shape[1]), dtype=Y.dtype)\n",
    "\n",
    "    out_index = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        #augment a random number of times inbetween 3 and 10 a random degree number between -30 and 30 degrees\n",
    "        X_out[out_index] = X[i]\n",
    "        Y_out[out_index] = Y[i]\n",
    "        out_index += 1\n",
    "        for k in range(numAugment[i]):\n",
    "            rand_rot = np.random.randint(-30, 30)\n",
    "            aug_image = rotate_same_dim(X[i], rand_rot)\n",
    "            X_out[out_index] = aug_image\n",
    "            Y_out[out_index] = Y[i]\n",
    "            out_index += 1\n",
    "    \n",
    "    return X_out, Y_out\n",
    "\n",
    "X_train_augmented, y_train = augment_train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_augmented.reshape((X_train_augmented.shape[0], X_train_augmented.shape[1]*X_train_augmented.shape[2])) # Flatten images\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]*X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate regressor and train data\n",
    "\n",
    "Variables in RandomForestRegressor can be changed, n_estimators is the number of trees used. Max_features is the number of features that one look for when splitting a node. None means max_features=n_estimators and is slower. \n",
    "\n",
    "Can also use decisitonTreeRegressor to omit the randomness of the randomForestDecisionTree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a tree without random forest\n",
    "regressor = DecisionTreeRegressor()\n",
    "multi_output_regressor = MultiOutputRegressor(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, max_features=None)\n",
    "# Create a MultiOutputRegressor\n",
    "multi_output_regressor = MultiOutputRegressor(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data\n",
    "multi_output_regressor.fit(X_train, y_train)\n",
    "#predict data\n",
    "predictions = multi_output_regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imag results: ROI1,\t ROI2,\t ROI3\n",
      "img0 actual: [3782000. 2899000.  958300.], avg: 2546433.3333333335\n",
      "img0 predic: [6444530. 2489340. 1858073.], avg: 3597314.3333333335, diff: [2662530.  409660.  899773.], tot diff: -3152643.0\n",
      "\n",
      "img1 actual: [2548000. 2123000.  678300.], avg: 1783100.0\n",
      "img1 predic: [10292610.  2488256.  2478550.], avg: 5086472.0, diff: [7744610.  365256. 1800250.], tot diff: -9910116.0\n",
      "\n",
      "img2 actual: [591000. 298200.  80110.], avg: 323103.3333333333\n",
      "img2 predic: [1210155.   551647.   257922.4], avg: 673241.4666666667, diff: [619155.  253447.  177812.4], tot diff: -1050414.4\n",
      "\n",
      "img3 actual: [8733000. 1911000.  761500.], avg: 3801833.3333333335\n",
      "img3 predic: [10020320.   2409945.   1406632.8], avg: 4612299.266666667, diff: [1287320.   498945.   645132.8], tot diff: -2431397.8\n",
      "\n",
      "img4 actual: [2223000. 1842000.  501300.], avg: 1522100.0\n",
      "img4 predic: [4197390. 2050806.  714103.], avg: 2320766.3333333335, diff: [1974390.  208806.  212803.], tot diff: -2395999.0\n",
      "\n",
      "img5 actual: [1852000.  733200.  260100.], avg: 948433.3333333334\n",
      "img5 predic: [4426615. 1793176.  875767.], avg: 2365186.0, diff: [2574615. 1059976.  615667.], tot diff: -4250258.0\n",
      "\n",
      "Total difference: 1333897.1222222224\n",
      "Average local diff: [2810436.66666667  466015.          725239.7       ]\n",
      "Variance  of diffs: [5.37402141e+12 7.97573235e+10 2.94466722e+11]\n"
     ]
    }
   ],
   "source": [
    "diff = np.zeros(3, dtype=float)\n",
    "tot_diff = 0\n",
    "i = 0\n",
    "diffs = np.zeros(predictions.shape, float)\n",
    "print(\"Imag results: ROI1,\\t ROI2,\\t ROI3\")\n",
    "for test, pred in zip(y_test, predictions):\n",
    "    d_test = test\n",
    "    d_pred = pred\n",
    "    # d_test = deNormalizeYresults(test, maks_y, min_y)\n",
    "    # d_pred = deNormalizeYresults(pred, maks_y, min_y)\n",
    "\n",
    "\n",
    "    print(f\"img{i} actual: {d_test}, avg: {np.sum(test)/3}\")\n",
    "    print(f\"img{i} predic: {d_pred}, avg: {np.sum(pred)/3}, diff: {abs(d_test - d_pred)}, tot diff: {np.sum(test-pred)}\")\n",
    "    print()\n",
    "    l_diff = np.abs(d_test-d_pred)\n",
    "    diffs[i] = l_diff\n",
    "    diff += l_diff\n",
    "    tot_diff += np.sum(l_diff)/3\n",
    "    i+=1\n",
    "\n",
    "print(f\"Total difference: {tot_diff/len(y_test)}\")\n",
    "print(f\"Average local diff: {diff/len(y_test)}\")\n",
    "print(f\"Variance  of diffs: {np.var(diffs, axis=0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinevision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
