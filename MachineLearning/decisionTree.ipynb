{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\MachineLearning\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "print(Path.cwd())\n",
    "sys.path.insert(0, str(Path.cwd() / \"..\"))\n",
    "from image_normalization.image_norm import setGrayToBlack, paddImage, rotate, rotate_same_dim\n",
    "from pymage_size import get_image_size\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are path, body, head, lung\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\MachineLearning\\decisionTree.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m images, y\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m images, y \u001b[39m=\u001b[39m readImages(\u001b[39mR\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msondr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOneDrive\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDokumenter\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTTT23\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTTT23_Project\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "\n",
    "def readImages(csvPath):    \n",
    "    \"\"\"\n",
    "    Reads the images, sets the grayscale values to black, i.e. removes all the area without a \n",
    "    heatmap. Converts remaining image to grayscale and pads, to make every image equal in size.\n",
    "    \n",
    "    TODO: instead of converting to grayscale with BGR2GRAY convert to grayscale where red is\n",
    "    white and purple is black\n",
    "\n",
    "    returns the images and an array y of the roi values. \n",
    "    \"\"\"\n",
    "    filenames = []\n",
    "    roi = []\n",
    "    max_shape = [0, 0]\n",
    "    with open(csvPath) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                path = Path.cwd() / \"..\" / row[0]\n",
    "                filenames.append(str(path))\n",
    "                img_size = get_image_size(str(path)).get_dimensions()[::-1]\n",
    "                if img_size[0] > max_shape[0]:\n",
    "                    max_shape[0] = img_size[0]\n",
    "                if img_size[1] > max_shape[1]:\n",
    "                    max_shape[1] = img_size[1]\n",
    "\n",
    "                roi.append([float(row[1]), float(row[2]), float(row[3])])\n",
    "\n",
    "    y = np.zeros((len(filenames), 3), float)\n",
    "    images = np.zeros((len(filenames), max_shape[0], max_shape[1]), dtype=np.uint8) \n",
    "    for i, filepath in enumerate(filenames):\n",
    "        img = cv.imread(str(filepath))\n",
    "        cv.imshow(\"img1\", img)\n",
    "        img_black = setGrayToBlack(img, threshold=150)\n",
    "        cv.imshow(\"img_gray_black\", img_black)\n",
    "\n",
    "        img_gray = cv.cvtColor(img_black, cv.COLOR_BGR2GRAY)\n",
    "        cv.imshow(\"img_gray\", img_gray)\n",
    "        img_pad = paddImage(img_gray, max_shape)\n",
    "        cv.imshow(\"pad\", img_pad)\n",
    "        images[i] = img_pad\n",
    "        y[i] = np.array(roi[i])\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "        return\n",
    "    return images, y\n",
    "\n",
    "images, y = readImages(R\"C:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\data.csv\")\n",
    "print(images.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split date into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment training set. This could be done on the initial set aswell, but then the test set would be of a \"lower\" quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\MachineLearning\\decisionTree.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             out_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m X_out, Y_out\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m X_train_augmented, y_train \u001b[39m=\u001b[39m augment_train(X_train, y_train)\n",
      "\u001b[1;32mc:\\Users\\sondr\\OneDrive\\Dokumenter\\a\\TTT23\\TTT23_Project\\MachineLearning\\decisionTree.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maugment_train\u001b[39m(X, Y):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     numAugment \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m, size\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(X)))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     X_out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(X) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msum(numAugment), X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], X\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m]), dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     Y_out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(Y) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msum(numAugment), Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), dtype\u001b[39m=\u001b[39mY\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sondr/OneDrive/Dokumenter/a/TTT23/TTT23_Project/MachineLearning/decisionTree.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     out_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def augment_train(X, Y):\n",
    "\n",
    "    numAugment = np.random.randint(3, 11, size=(len(X)))\n",
    "    X_out = np.zeros((len(X) + np.sum(numAugment), X.shape[1], X.shape[2]), dtype=X.dtype)\n",
    "    Y_out = np.zeros((len(Y) + np.sum(numAugment), Y.shape[1]), dtype=Y.dtype)\n",
    "\n",
    "    out_index = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        #augment a random number of times inbetween 3 and 10 a random degree number between -30 and 30 degrees\n",
    "        X_out[out_index] = X[i]\n",
    "        Y_out[out_index] = Y[i]\n",
    "        out_index += 1\n",
    "        for k in range(numAugment[i]):\n",
    "            rand_rot = np.random.randint(-30, 30)\n",
    "            aug_image = rotate_same_dim(X[i], rand_rot)\n",
    "            X_out[out_index] = aug_image\n",
    "            Y_out[out_index] = Y[i]\n",
    "            out_index += 1\n",
    "    \n",
    "    return X_out, Y_out\n",
    "\n",
    "X_train_augmented, y_train = augment_train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493, 81753)\n",
      "(17, 81753)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_augmented.reshape((X_train_augmented.shape[0], X_train_augmented.shape[1]*X_train_augmented.shape[2])) # Flatten images\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 81753)\n",
      "(17, 81753)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate regressor and train data\n",
    "\n",
    "Variables in RandomForestRegressor can be changed, n_estimators is the number of trees used. Max_features is the number of features that one look for when splitting a node. None means max_features=n_estimators and is slower. \n",
    "\n",
    "Can also use decisitonTreeRegressor to omit the randomness of the randomForestDecisionTree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a tree without random forest\n",
    "regressor = DecisionTreeRegressor()\n",
    "multi_output_regressor = MultiOutputRegressor(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, max_features='sqrt')\n",
    "# Create a MultiOutputRegressor\n",
    "multi_output_regressor = MultiOutputRegressor(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data\n",
    "multi_output_regressor.fit(X_train, y_train)\n",
    "#predict data\n",
    "predictions = multi_output_regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imag results: ROI1,\t ROI2,\t ROI3\n",
      "img0 actual: [1991000.  498600.  157600.], avg: 882400.0\n",
      "img0 predic: [2152905.   914040.   288089.2], avg: 1118344.7333333334, diff: [161905.  415440.  130489.2], tot diff: -707834.2\n",
      "\n",
      "img1 actual: [3710000. 2826000.  820300.], avg: 2452100.0\n",
      "img1 predic: [4762920. 2283992.  803325.], avg: 2616745.6666666665, diff: [1052920.  542008.   16975.], tot diff: -493937.0\n",
      "\n",
      "img2 actual: [2385000.  977600.  259500.], avg: 1207366.6666666667\n",
      "img2 predic: [3036835. 1725317.  600180.], avg: 1787444.0, diff: [651835. 747717. 340680.], tot diff: -1740232.0\n",
      "\n",
      "img3 actual: [4057000.  623700.  231500.], avg: 1637400.0\n",
      "img3 predic: [3520590.   646265.   285846.6], avg: 1484233.8666666665, diff: [536410.   22565.   54346.6], tot diff: 459498.4\n",
      "\n",
      "img4 actual: [3205000. 2362000.  909000.], avg: 2158666.6666666665\n",
      "img4 predic: [3294460.  1956331.   632583.1], avg: 1961124.7, diff: [ 89460.  405669.  276416.9], tot diff: 592625.9\n",
      "\n",
      "img5 actual: [8474000. 1866000.  849100.], avg: 3729700.0\n",
      "img5 predic: [3963190. 1467448.  585428.], avg: 2005355.3333333333, diff: [4510810.  398552.  263672.], tot diff: 5173034.0\n",
      "\n",
      "img6 actual: [7442000. 3440000. 1252000.], avg: 4044666.6666666665\n",
      "img6 predic: [3397710.  1704541.   490254.4], avg: 1864168.4666666668, diff: [4044290.  1735459.   761745.6], tot diff: 6541494.6\n",
      "\n",
      "img7 actual: [2385000.  977600.  259500.], avg: 1207366.6666666667\n",
      "img7 predic: [15304605.   1846324.   2159873.8], avg: 6436934.266666667, diff: [12919605.    868724.   1900373.8], tot diff: -15688702.8\n",
      "\n",
      "img8 actual: [7442000. 3440000. 1252000.], avg: 4044666.6666666665\n",
      "img8 predic: [2358785.  1261807.   463958.7], avg: 1361516.9000000001, diff: [5083215.  2178193.   788041.3], tot diff: 8049449.3\n",
      "\n",
      "img9 actual: [29230000.  1587000.  6956000.], avg: 12591000.0\n",
      "img9 predic: [9805755.  1718352.   935836.2], avg: 4153314.4, diff: [19424245.    131352.   6020163.8], tot diff: 25313056.8\n",
      "\n",
      "img10 actual: [29230000.  1587000.  6956000.], avg: 12591000.0\n",
      "img10 predic: [9269835.  1173415.  1128958.4], avg: 3857402.8000000003, diff: [19960165.    413585.   5827041.6], tot diff: 26200791.6\n",
      "\n",
      "img11 actual: [2503000. 2005000.  630800.], avg: 1712933.3333333333\n",
      "img11 predic: [4790030. 1868440.  654699.], avg: 2437723.0, diff: [2287030.  136560.   23899.], tot diff: -2174369.0\n",
      "\n",
      "img12 actual: [591000. 298200.  80110.], avg: 323103.3333333333\n",
      "img12 predic: [2481785.  677516.  316898.], avg: 1158733.0, diff: [1890785.  379316.  236788.], tot diff: -2506889.0\n",
      "\n",
      "img13 actual: [1790000.  821300.  325400.], avg: 978900.0\n",
      "img13 predic: [2912735.  1275287.   419061.1], avg: 1535694.3666666665, diff: [1122735.   453987.    93661.1], tot diff: -1670383.1\n",
      "\n",
      "img14 actual: [1790000.  821300.  325400.], avg: 978900.0\n",
      "img14 predic: [1909795.  1066412.   283026.5], avg: 1086411.1666666667, diff: [119795.  245112.   42373.5], tot diff: -322533.5\n",
      "\n",
      "img15 actual: [2617000. 1838000.  721300.], avg: 1725433.3333333333\n",
      "img15 predic: [4487390.  2016071.   731362.1], avg: 2411607.6999999997, diff: [1870390.   178071.    10062.1], tot diff: -2058523.1\n",
      "\n",
      "img16 actual: [2320000.  571600.  200500.], avg: 1030700.0\n",
      "img16 predic: [4464940.  1339767.   619009.9], avg: 2141238.966666667, diff: [2144940.   768167.   418509.9], tot diff: -3331616.9\n",
      "\n",
      "Total difference: 2060710.8117647062\n",
      "Average local diff: [4580619.70588235  589439.82352941 1012072.90588235]\n",
      "Variance  of diffs: [6270886.02750147  552679.51260023 1849025.75333401]\n"
     ]
    }
   ],
   "source": [
    "diff = np.zeros(3, dtype=float)\n",
    "tot_diff = 0\n",
    "i = 0\n",
    "diffs = np.zeros(predictions.shape, float)\n",
    "print(\"Imag results: ROI1,\\t ROI2,\\t ROI3\")\n",
    "for test, pred in zip(y_test, predictions):\n",
    "    d_test = test\n",
    "    d_pred = pred\n",
    "    # d_test = deNormalizeYresults(test, maks_y, min_y)\n",
    "    # d_pred = deNormalizeYresults(pred, maks_y, min_y)\n",
    "\n",
    "\n",
    "    print(f\"img{i} actual: {d_test}, avg: {np.sum(test)/3}\")\n",
    "    print(f\"img{i} predic: {d_pred}, avg: {np.sum(pred)/3}, diff: {abs(d_test - d_pred)}, tot diff: {np.sum(test-pred)}\")\n",
    "    print()\n",
    "    l_diff = np.abs(d_test-d_pred)\n",
    "    diffs[i] = l_diff\n",
    "    diff += l_diff\n",
    "    tot_diff += np.sum(l_diff)/3\n",
    "    i+=1\n",
    "\n",
    "print(f\"Total difference: {tot_diff/len(y_test)}\")\n",
    "print(f\"Average local diff: {diff/len(y_test)}\")\n",
    "print(f\"Variance  of diffs: {np.sqrt(np.var(diffs, axis=0))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinevision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
